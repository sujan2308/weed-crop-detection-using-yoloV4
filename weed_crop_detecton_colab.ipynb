{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujan2308/weed-crop-detection-using-yoloV4/blob/main/weed_crop_detecton_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the required libraries"
      ],
      "metadata": {
        "id": "oLMFBIWxcwO4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "jdzMhQv6HZlz",
        "outputId": "ca97cb4c-ef16-43fd-b5af-58199cd84662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-contrib-python==4.6.0.66\n",
            "  Downloading opencv_contrib_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.6\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, opencv-contrib-python\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.7.0.72\n",
            "    Uninstalling opencv-contrib-python-4.7.0.72:\n",
            "      Successfully uninstalled opencv-contrib-python-4.7.0.72\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.21.6 opencv-contrib-python-4.6.0.66\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install opencv-contrib-python==4.6.0.66 numpy==1.21.6 --force-reinstall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT_5PThXK1zk",
        "outputId": "76c53738-10f1-408c-ce59-fd32e57846bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yolo\n",
            "  Downloading yolo-0.3.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting awscli (from yolo)\n",
            "  Downloading awscli-1.27.140-py3-none-any.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3 (from yolo)\n",
            "  Downloading boto3-1.26.140-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore>=1.7.18 (from yolo)\n",
            "  Downloading botocore-1.29.140-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from yolo) (8.1.3)\n",
            "Collecting docker==3.4.0 (from yolo)\n",
            "  Downloading docker-3.4.0-py2.py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from yolo) (3.1.2)\n",
            "Collecting keyring==8.7.0 (from yolo)\n",
            "  Downloading keyring-8.7-py2.py3-none-any.whl (33 kB)\n",
            "Collecting keyrings.alt (from yolo)\n",
            "  Downloading keyrings.alt-4.2.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from yolo) (2.27.1)\n",
            "Collecting ruamel.yaml (from yolo)\n",
            "  Downloading ruamel.yaml-0.17.26-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from yolo) (0.8.10)\n",
            "Collecting voluptuous (from yolo)\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker==3.4.0->yolo) (1.16.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker==3.4.0->yolo) (1.5.1)\n",
            "Collecting docker-pycreds>=0.3.0 (from docker==3.4.0->yolo)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore>=1.7.18->yolo)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore>=1.7.18->yolo) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore>=1.7.18->yolo) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->yolo) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->yolo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->yolo) (3.4)\n",
            "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.10/dist-packages (from awscli->yolo) (0.16)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from awscli->yolo)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML<5.5,>=3.10 (from awscli->yolo)\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama<0.4.5,>=0.2.5 (from awscli->yolo)\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli->yolo)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->yolo) (2.1.2)\n",
            "Collecting jaraco.classes (from keyrings.alt->yolo)\n",
            "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->yolo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli->yolo) (0.5.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from jaraco.classes->keyrings.alt->yolo) (9.1.0)\n",
            "Building wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=048e2d4b868d9bbb8762f2a8b5f3a3701cbcdb5f90045d94b50076c25ca091ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: voluptuous, keyring, ruamel.yaml.clib, rsa, PyYAML, jmespath, jaraco.classes, docker-pycreds, colorama, ruamel.yaml, keyrings.alt, docker, botocore, s3transfer, boto3, awscli, yolo\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-5.4.1 awscli-1.27.140 boto3-1.26.140 botocore-1.29.140 colorama-0.4.4 docker-3.4.0 docker-pycreds-0.4.0 jaraco.classes-3.2.3 jmespath-1.0.1 keyring-8.7 keyrings.alt-4.2.0 rsa-4.7.2 ruamel.yaml-0.17.26 ruamel.yaml.clib-0.2.7 s3transfer-0.6.1 voluptuous-0.13.1 yolo-0.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install yolo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import your Google drive to Colab notebook"
      ],
      "metadata": {
        "id": "BWdiMHA_c2Jn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4WXqdSdIs0n",
        "outputId": "c8883985-5b03-4e1e-86c8-91c6ec108166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the Yolov4.zip file and store the file in folder named Yolov4"
      ],
      "metadata": {
        "id": "Ep_wJKrvi4Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Yolov4.zip\" -d \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "E61Y6LIIi22x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuwNgNKMLQIr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3EgpomyLxlN",
        "outputId": "75836402-be89-479a-9090-1df84e1c9a7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement core (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for core\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rk-_DdlIJKqF"
      },
      "outputs": [],
      "source": [
        "!ln -s /content/drive/MyDrive/ /mydrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Ma3XcqNJpaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f8c5d4-d0cb-43c7-a195-ef2d60cdb83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " convert_tflite.py   object\t    object.zip\t    training\n",
            " darknet\t     object.data    process.py\t    yolov4-custom.cfg\n",
            "'darknet (1)'\t     object.names   save_model.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!ls /mydrive/Yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdsTxJXw0Bg6",
        "outputId": "4934dc21-7a31-4978-e001-08be418d46e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-06 08:33:46.504827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Yolov4/darknet/save_model.py\", line 4, in <module>\n",
            "    from core.yolov4 import YOLO, decode, filter_boxes\n",
            "ModuleNotFoundError: No module named 'core'\n"
          ]
        }
      ],
      "source": [
        "!python save_model.py --weights ./mydrive/Yolov4/training/yolov4-custom_last.weights --output ./content/yolov4-416 --input_size 416 --model yolov4 --framework tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C362RrPD0CAV",
        "outputId": "4ad509fd-f125-488d-f38f-f4d142f8c7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-06 06:56:41.916966: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "ImportError: numpy.core._multiarray_umath failed to import\n",
            "ImportError: numpy.core.umath failed to import\n",
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "ImportError: numpy.core._multiarray_umath failed to import\n",
            "ImportError: numpy.core.umath failed to import\n",
            "RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe\n",
            "ImportError: numpy.core._multiarray_umath failed to import\n",
            "ImportError: numpy.core.umath failed to import\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Yolov4/darknet/convert_tflite.py\", line 1, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py\", line 42, in <module>\n",
            "    from tensorflow.python import data\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n",
            "    from tensorflow.python.data import experimental\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/__init__.py\", line 97, in <module>\n",
            "    from tensorflow.python.data.experimental import service\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n",
            "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 22, in <module>\n",
            "    from tensorflow.python.data.experimental.ops import compression_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\", line 16, in <module>\n",
            "    from tensorflow.python.data.util import structure\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/structure.py\", line 22, in <module>\n",
            "    from tensorflow.python.data.util import nest\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/util/nest.py\", line 34, in <module>\n",
            "    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/sparse_tensor.py\", line 25, in <module>\n",
            "    from tensorflow.python.framework import constant_op\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 25, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py\", line 37, in <module>\n",
            "    _np_bfloat16 = _pywrap_bfloat16.TF_bfloat16_type()\n",
            "TypeError: Unable to convert function return value to a Python type! The signature was\n",
            "\t() -> handle\n"
          ]
        }
      ],
      "source": [
        "!python convert_tflite.py --weights ./content/yolov4-416 --output ./checkpoints/yolov4-416.tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEJZo4HAJtI3",
        "outputId": "25b88767-a8a1-4adf-e25d-b378aeb191b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path '/mydrive/Yolov4/darknet' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/AlexeyAB/darknet.git /mydrive/Yolov4/darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oee2YHMNJ0sg",
        "outputId": "cc845740-e623-4f52-8c3d-2598573a8f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Yolov4/darknet\n"
          ]
        }
      ],
      "source": [
        "%cd /mydrive/Yolov4/darknet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDWINmWtJ9W8",
        "outputId": "41cd24cc-f42e-4aec-8e1b-c55e9baaf4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3rdparty\t\t image_yolov3.sh\tsrc\n",
            "backup\t\t\t image_yolov4.sh\tuselib\n",
            "build\t\t\t include\t\tvcpkg.json\n",
            "build.ps1\t\t json_mjpeg_streams.sh\tvcpkg.json.opencv23\n",
            "cfg\t\t\t libdarknet.so\t\tvideo_yolov3.sh\n",
            "chart.png\t\t LICENSE\t\tvideo_yolov4.sh\n",
            "chart_yolov4-custom.png  Makefile\t\tyolov4.conv.137\n",
            "cmake\t\t\t net_cam_v3.sh\t\tyolov4.conv.137.1\n",
            "CMakeLists.txt\t\t net_cam_v4.sh\t\tyolov4.conv.137.2\n",
            "darknet\t\t\t obj\t\t\tyolov4.conv.137.3\n",
            "DarknetConfig.cmake.in\t object\t\t\tyolov4.conv.137.4\n",
            "darknet_images.py\t process.py\t\tyolov4.conv.137.5\n",
            "darknet.py\t\t README.md\t\tyolov4.conv.137.6\n",
            "darknet_video.py\t results\t\tyolov4.conv.137.7\n",
            "data\t\t\t scripts\t\tyolov4.conv.137.8\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!ls /mydrive/Yolov4/darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHg2gkGuKAjG"
      },
      "outputs": [],
      "source": [
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhl1WYmtKRi_"
      },
      "outputs": [],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyAeqIBkKWp9",
        "outputId": "f1822fbc-da68-4246-bbf5-235629d49a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Yolov4/darknet/data\n",
            "/content/drive/MyDrive/Yolov4/darknet\n"
          ]
        }
      ],
      "source": [
        "%cd data/\n",
        "!find -maxdepth 1 -type f -exec rm -rf {} \\;\n",
        "%cd ..\n",
        "%rm -rf cfg/\n",
        "%mkdir cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQkRs-XgK8E7"
      },
      "outputs": [],
      "source": [
        "!unzip /mydrive/Yolov4/object.zip -d object/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzdxstEnK_hC"
      },
      "outputs": [],
      "source": [
        "!cp /mydrive/Yolov4/yolov4-custom.cfg cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7lVHpjfLI-8"
      },
      "outputs": [],
      "source": [
        "!cp /mydrive/Yolov4/object.names data\n",
        "!cp /mydrive/Yolov4/object.data  data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-VjTCvoLQRk"
      },
      "outputs": [],
      "source": [
        "\n",
        "!cp /mydrive/Yolov4/process.py ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clAY2PqmLZHz"
      },
      "outputs": [],
      "source": [
        "!python process.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFFtVMC1Lc2B",
        "outputId": "43693bfc-683c-4314-f47d-4a6f607122c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels\tobject\tobject.data  object.names  test.txt  train.txt\n"
          ]
        }
      ],
      "source": [
        "!ls data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rPNmT46LnX6"
      },
      "outputs": [],
      "source": [
        "!cat data/test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-2XT-oLNxjs"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the traied model"
      ],
      "metadata": {
        "id": "curnbhoKMk4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v4ir7f5N2qd"
      },
      "outputs": [],
      "source": [
        "!./darknet detector train data/object.data cfg/yolov4-custom.cfg yolov4.conv.137 -dont_show -map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfcC5MOJyxcE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZw60cgXN_4E"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "import html\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxRkqYaxPk1M"
      },
      "outputs": [],
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9RgdfvGWKTF"
      },
      "outputs": [],
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 640);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"Status:\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '' +\n",
        "          'When finished, click here or on the video to stop this demo';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 640; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "kV7EvcSMWZQW",
        "outputId": "9e18c4bf-6669-4980-8152-ec4f86c4b8f8"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 640);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"Status:\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '' +\n",
              "          'When finished, click here or on the video to stop this demo';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 640; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0\n",
        "\n",
        "# load our YOLO object detector trained on our custom dataset dataset (02 classes)\n",
        "net = cv2.dnn.readNetFromDarknet('cfg/yolov4-custom.cfg', '../training/yolov4-custom_last.weights')\n",
        "ln = net.getLayerNames()\n",
        "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "DEFAULT_CONFIANCE = 0.4\n",
        "THRESHOLD = 0.3\n",
        "# load the COCO class labels our YOLO model was trained on\n",
        "with open('data/object.names', 'r') as f:\n",
        "    LABELS = f.read().splitlines()\n",
        "\n",
        "# initialize the video stream, pointer to output video file\n",
        "#cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    image = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    #_,image=cap.read()\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(image, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    layerOutputs = net.forward(ln)\n",
        "\n",
        "    # initialize our lists of detected bounding boxes, confidences, and class IDs, respectively\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    classIDs = []\n",
        "\n",
        "    # loop over each of the layer outputs\n",
        "    for output in layerOutputs:\n",
        "        # loop over each of the detections\n",
        "        for detection in output:\n",
        "            # extract the class ID and confidence (i.e., probability)\n",
        "            # of the current object detection\n",
        "            scores = detection[5:]\n",
        "            classID = np.argmax(scores)\n",
        "            confidence = scores[classID]\n",
        "            # filter out weak predictions by ensuring the detected\n",
        "            # probability is greater than the minimum probability\n",
        "            if confidence > DEFAULT_CONFIANCE:\n",
        "                # scale the bounding box coordinates back relative to\n",
        "                # the size of the image, keeping in mind that YOLO\n",
        "                # actually returns the center (x, y)-coordinates of\n",
        "                # the bounding box followed by the boxes' width and\n",
        "                # height\n",
        "                box = detection[0:4] * np.array([width, height, width, height])\n",
        "                (centerX, centerY, W, H) = box.astype(\"int\")\n",
        "                # use the center (x, y)-coordinates to derive the top\n",
        "                # and and left corner of the bounding box\n",
        "                x = int(centerX - (W / 2))\n",
        "                y = int(centerY - (H / 2))\n",
        "                # update our list of bounding box coordinates,\n",
        "                # confidences, and class IDs\n",
        "                boxes.append([x, y, int(W), int(H)])\n",
        "                confidences.append(float(confidence))\n",
        "                classIDs.append(classID)\n",
        "\n",
        "    # apply non-maxima suppression to suppress weak, overlapping\n",
        "    # bounding boxes\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, DEFAULT_CONFIANCE, THRESHOLD)\n",
        "\n",
        "    # initialize a list of colors to represent each possible class label\n",
        "    COLORS = np.random.uniform(0,255,size=(len(boxes), 3))\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([640,640,4], dtype=np.uint8)\n",
        "\n",
        "    # ensure at least one detection exists\n",
        "    if len(indexes) > 0:\n",
        "        # loop over the indexes we are keeping\n",
        "        for i in indexes.flatten():\n",
        "            # extract the bounding box coordinates\n",
        "            (x, y, w, h) = boxes[i]\n",
        "            # draw a bounding box rectangle and label on the frame\n",
        "            color = COLORS[i]\n",
        "            text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
        "            bbox_array = cv2.rectangle(bbox_array, (x, y), (x + w, y + h), color, 2)\n",
        "            bbox_array = cv2.putText(bbox_array, text, (x, y + 20 ), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
        "\n",
        "    #cv2.imshow('Image', image)\n",
        "    #if cv2.waitKey(1)==ord('q'):\n",
        "     #   break\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM7u4-pQXAgs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsIGEBOAGyoh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgqdJta7jsJapTFFVWK9Ii",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}